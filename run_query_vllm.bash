# python query_vllm.py --task MolEdit --subtask AddComponent --json_check --port 8002 --name llama3-8B --model meta-llama/Meta-Llama-3-8B-Instruct --output_dir ./predictions/
# python query_vllm.py --task MolEdit --subtask DelComponent --json_check --port 8002 --name llama3-8B --model meta-llama/Meta-Llama-3-8B-Instruct --output_dir ./predictions/
# python query_vllm.py --task MolEdit --subtask SubComponent --json_check --port 8002 --name llama3-8B --model meta-llama/Meta-Llama-3-8B-Instruct --output_dir ./predictions/

# python query_vllm.py --task MolCustom --subtask AtomNum --json_check --port 8002 --name llama3-8B --model meta-llama/Meta-Llama-3-8B-Instruct --output_dir ./predictions/
# python query_vllm.py --task MolCustom --subtask BondNum --json_check --port 8002 --name llama3-8B --model meta-llama/Meta-Llama-3-8B-Instruct --output_dir ./predictions/
# python query_vllm.py --task MolCustom --subtask FunctionalGroup --json_check --port 8002 --name llama3-8B --model meta-llama/Meta-Llama-3-8B-Instruct --output_dir ./predictions/

# python query_vllm.py --task MolOpt --subtask LogP --json_check --port 8002 --name llama3-8B --model meta-llama/Meta-Llama-3-8B-Instruct --output_dir ./predictions/
# python query_vllm.py --task MolOpt --subtask MR --json_check --port 8002 --name llama3-8B --model meta-llama/Meta-Llama-3-8B-Instruct --output_dir ./predictions/
# python query_vllm.py --task MolOpt --subtask QED --json_check --port 8002 --name llama3-8B --model meta-llama/Meta-Llama-3-8B-Instruct --output_dir ./predictions/


# python query_vllm.py --task MolEdit --subtask AddComponent --json_check --port 8003 --name meditron3-8B --model OpenMeditron/Meditron3-8B
# python query_vllm.py --task MolEdit --subtask DelComponent --json_check --port 8003 --name meditron3-8B --model OpenMeditron/Meditron3-8B
# python query_vllm.py --task MolEdit --subtask SubComponent --json_check --port 8003 --name meditron3-8B --model OpenMeditron/Meditron3-8B

# python query_vllm.py --task MolCustom --subtask AtomNum --json_check --port 8003 --name meditron3-8B --model OpenMeditron/Meditron3-8B
# python query_vllm.py --task MolCustom --subtask BondNum --json_check --port 8003 --name meditron3-8B --model OpenMeditron/Meditron3-8B
# python query_vllm.py --task MolCustom --subtask FunctionalGroup --json_check --port 8003 --name meditron3-8B --model OpenMeditron/Meditron3-8B

# python query_vllm.py --task MolOpt --subtask LogP --json_check --port 8003 --name meditron3-8B --model OpenMeditron/Meditron3-8B
# python query_vllm.py --task MolOpt --subtask MR --json_check --port 8003 --name meditron3-8B --model OpenMeditron/Meditron3-8B
# python query_vllm.py --task MolOpt --subtask QED --json_check --port 8003 --name meditron3-8B --model OpenMeditron/Meditron3-8B

# python query_vllm.py --task MolEdit --subtask AddComponent --json_check --port 8003 --name meditron-7B --model epfl-llm/meditron-7b
# python query_vllm.py --task MolEdit --subtask DelComponent --json_check --port 8003 --name meditron-7B --model epfl-llm/meditron-7b
# python query_vllm.py --task MolEdit --subtask SubComponent --json_check --port 8003 --name meditron-7B --model epfl-llm/meditron-7b

# python query_vllm.py --task MolCustom --subtask AtomNum --json_check --port 8003 --name meditron-7B --model epfl-llm/meditron-7b
# python query_vllm.py --task MolCustom --subtask BondNum --json_check --port 8003 --name meditron-7B --model epfl-llm/meditron-7b
# python query_vllm.py --task MolCustom --subtask FunctionalGroup --json_check --port 8003 --name meditron-7B --model epfl-llm/meditron-7b

# python query_vllm.py --task MolOpt --subtask LogP --json_check --port 8003 --name meditron-7B --model epfl-llm/meditron-7b
# python query_vllm.py --task MolOpt --subtask MR --json_check --port 8003 --name meditron-7B --model epfl-llm/meditron-7b
# python query_vllm.py --task MolOpt --subtask QED --json_check --port 8003 --name meditron-7B --model epfl-llm/meditron-7b

# python query_vllm.py --task MolCustom --subtask AtomNum --json_check --port 8001 --name mistral-7B --model mistralai/Mistral-7B-Instruct-v0.2 --output_dir ./predictions/
# python query_vllm.py --task MolCustom --subtask BondNum --json_check --port 8001 --name mistral-7B --model mistralai/Mistral-7B-Instruct-v0.2 --output_dir ./predictions/
# python query_vllm.py --task MolCustom --subtask FunctionalGroup --json_check --port 8001 --name mistral-7B --model mistralai/Mistral-7B-Instruct-v0.2 --output_dir ./predictions/

# python query_vllm.py --task MolEdit --subtask AddComponent --json_check --port 8001 --name mistral-7B --model mistralai/Mistral-7B-Instruct-v0.2 --output_dir ./predictions/
# python query_vllm.py --task MolEdit --subtask DelComponent --json_check --port 8001 --name mistral-7B --model mistralai/Mistral-7B-Instruct-v0.2 --output_dir ./predictions/
# python query_vllm.py --task MolEdit --subtask SubComponent --json_check --port 8001 --name mistral-7B --model mistralai/Mistral-7B-Instruct-v0.2 --output_dir ./predictions/

# python query_vllm.py --task MolOpt --subtask LogP --json_check --port 8001 --name mistral-7B --model mistralai/Mistral-7B-Instruct-v0.2 --output_dir ./predictions/
# python query_vllm.py --task MolOpt --subtask MR --json_check --port 8001 --name mistral-7B --model mistralai/Mistral-7B-Instruct-v0.2 --output_dir ./predictions/
# python query_vllm.py --task MolOpt --subtask QED --json_check --port 8001 --name mistral-7B --model mistralai/Mistral-7B-Instruct-v0.2 --output_dir ./predictions/


# python query_vllm.py --task MolCustom --subtask AtomNum --json_check --port 8001 --name llama3.2-1B --model meta-llama/Llama-3.2-1B-Instruct --output_dir ./predictions/
# python query_vllm.py --task MolCustom --subtask BondNum --json_check --port 8001 --name llama3.2-1B --model meta-llama/Llama-3.2-1B-Instruct --output_dir ./predictions/
# python query_vllm.py --task MolCustom --subtask FunctionalGroup --json_check --port 8001 --name llama3.2-1B --model meta-llama/Llama-3.2-1B-Instruct --output_dir ./predictions/

# python query_vllm.py --task MolEdit --subtask AddComponent --json_check --port 8001 --name llama3.2-1B --model meta-llama/Llama-3.2-1B-Instruct --output_dir ./predictions/
# python query_vllm.py --task MolEdit --subtask DelComponent --json_check --port 8001 --name llama3.2-1B --model meta-llama/Llama-3.2-1B-Instruct --output_dir ./predictions/
# python query_vllm.py --task MolEdit --subtask SubComponent --json_check --port 8001 --name llama3.2-1B --model meta-llama/Llama-3.2-1B-Instruct --output_dir ./predictions/

# python query_vllm.py --task MolOpt --subtask LogP --json_check --port 8001 --name llama3.2-1B --model meta-llama/Llama-3.2-1B-Instruct --output_dir ./predictions/
# python query_vllm.py --task MolOpt --subtask MR --json_check --port 8001 --name llama3.2-1B --model meta-llama/Llama-3.2-1B-Instruct --output_dir ./predictions/
# python query_vllm.py --task MolOpt --subtask QED --json_check --port 8001 --name llama3.2-1B --model meta-llama/Llama-3.2-1B-Instruct --output_dir ./predictions/


# python query_vllm.py --task MolCustom --subtask AtomNum --json_check --port 8001 --name llama3.1-8B --model meta-llama/Llama-3.1-8B-Instruct --output_dir ./predictions/
# python query_vllm.py --task MolCustom --subtask BondNum --json_check --port 8000 --name llama3.1-8B --model meta-llama/Llama-3.1-8B-Instruct --output_dir ./predictions/
# python query_vllm.py --task MolCustom --subtask FunctionalGroup --json_check --port 8000 --name llama3.1-8B --model meta-llama/Llama-3.1-8B-Instruct --output_dir ./predictions/

# python query_vllm.py --task MolEdit --subtask AddComponent --json_check --port 8001 --name llama3.1-8B --model meta-llama/Llama-3.1-8B-Instruct --output_dir ./predictions/
# python query_vllm.py --task MolEdit --subtask DelComponent --json_check --port 8001 --name llama3.1-8B --model meta-llama/Llama-3.1-8B-Instruct --output_dir ./predictions/
# python query_vllm.py --task MolEdit --subtask SubComponent --json_check --port 8001 --name llama3.1-8B --model meta-llama/Llama-3.1-8B-Instruct --output_dir ./predictions/

# python query_vllm.py --task MolOpt --subtask LogP --json_check --port 8002 --name llama3.1-8B --model meta-llama/Llama-3.1-8B-Instruct --output_dir ./predictions/
# python query_vllm.py --task MolOpt --subtask MR --json_check --port 8002 --name llama3.1-8B --model meta-llama/Llama-3.1-8B-Instruct --output_dir ./predictions/
# python query_vllm.py --task MolOpt --subtask QED --json_check --port 8002 --name llama3.1-8B --model meta-llama/Llama-3.1-8B-Instruct --output_dir ./predictions/
